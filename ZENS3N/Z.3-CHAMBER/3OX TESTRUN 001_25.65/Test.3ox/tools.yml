///▙▖▙▖▞▞▙▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
▛//▞▞ ⟦⎊⟧ :: ⧗-25.61 ▸ ρ{tool.runtime}.φ{registry}.τ{execute}.λ{bind} ⫸ :: TOOLS.RS

use std::collections::HashMap;
use std::fs::{self, File};
use std::io::{Read, Write};
use std::path::{Path, PathBuf};
use std::process::Command;
use std::time::{SystemTime, UNIX_EPOCH};

use serde::{Deserialize, Serialize};
use serde_json::json;
use sha2::{Digest, Sha256};
use tiktoken_rs::{cl100k_base, o200k_base};
use walkdir::WalkDir;

/// Toolset Version
pub const VERSION: &str = "v2.1.0";

/// Available Tools (subset of global registry)
#[derive(Debug, Clone)]
pub enum Tool {
    // File Operations
    FileValidator,
    ConflictResolver,
    
    // Git Operations
    GitPusher,
    GitPuller,
    
    // Receipt System
    ReceiptGenerator,
    ReceiptValidator,
    
    // Deployment
    DeployValidator,
    CloudManager,
    CostTracker,
    
    // Knowledge
    LibraryCatalog,
    LinkValidator,
    MOCGenerator,
    
    // Token Management (NEW)
    TokenCounter,
    ContextAnalyzer,
    CostEstimator,
}

impl Tool {
    /// Execute tool with input
    pub fn execute(&self, input: &str) -> Result<String, String> {
        match self {
            Tool::FileValidator => validate_file(input),
            Tool::ConflictResolver => resolve_conflict(input),
            Tool::GitPusher => push_to_git(input),
            Tool::GitPuller => pull_from_git(input),
            Tool::ReceiptGenerator => generate_receipt(input),
            Tool::ReceiptValidator => validate_receipt(input),
            Tool::DeployValidator => validate_deployment(input),
            Tool::CloudManager => manage_cloud(input),
            Tool::CostTracker => track_costs(input),
            Tool::LibraryCatalog => catalog_library(input),
            Tool::LinkValidator => validate_links(input),
            Tool::MOCGenerator => generate_moc(input),
            Tool::TokenCounter => count_tokens(input),
            Tool::ContextAnalyzer => analyze_context(input),
            Tool::CostEstimator => estimate_cost(input),
        }
    }
    
    /// Get tool description
    pub fn description(&self) -> &'static str {
        match self {
            Tool::FileValidator => "Validates file integrity with SHA256 checksum",
            Tool::ConflictResolver => "Resolves sync conflicts using last-write-wins",
            Tool::GitPusher => "Pushes to Git with atomic operations",
            Tool::GitPuller => "Pulls from Git safely",
            Tool::ReceiptGenerator => "Generates cryptographic receipt for file",
            Tool::ReceiptValidator => "Validates receipt against file hash",
            Tool::DeployValidator => "Validates deployment readiness",
            Tool::CloudManager => "Manages cloud resources",
            Tool::CostTracker => "Tracks operational costs",
            Tool::LibraryCatalog => "Catalogs library entries",
            Tool::LinkValidator => "Validates note links",
            Tool::MOCGenerator => "Generates Map of Content",
            Tool::TokenCounter => "Counts tokens for AI model input",
            Tool::ContextAnalyzer => "Analyzes context size and token distribution",
            Tool::CostEstimator => "Summarizes token counts",
        }
    }
}

// ============================================================================
// Tool Implementations
// ============================================================================

fn validate_file(path: &str) -> Result<String, String> {
    let trimmed = path.trim();
    if trimmed.is_empty() {
        return Err("Path required".to_string());
    }

    let path = Path::new(trimmed);
    if !path.exists() {
        return Err(format!("File not found: {}", path.display()));
    }
    if !path.is_file() {
        return Err(format!("Path is not a file: {}", path.display()));
    }

    let metadata = fs::metadata(path).map_err(|err| err.to_string())?;
    let hash = compute_sha256(path).map_err(|err| err.to_string())?;
    let modified = metadata
        .modified()
        .ok()
        .and_then(iso_timestamp)
        .unwrap_or_default();

    let payload = json!({
        "path": path.to_string_lossy(),
        "size_bytes": metadata.len(),
        "modified": modified,
        "sha256": hash,
        "status": "valid"
    });

    Ok(payload.to_string())
}

fn resolve_conflict(files: &str) -> Result<String, String> {
    let candidates: Vec<PathBuf> = files
        .split(|c| c == '|' || c == ',')
        .map(|entry| entry.trim())
        .filter(|entry| !entry.is_empty())
        .map(PathBuf::from)
        .collect();

    if candidates.len() < 2 {
        return Err("Provide at least two file paths separated by '|' or ','".to_string());
    }

    let mut newest: Option<(PathBuf, SystemTime)> = None;
    for path in &candidates {
        let metadata = fs::metadata(path)
            .map_err(|err| format!("{}: {}", path.display(), err))?;
        let modified = metadata
            .modified()
            .map_err(|err| format!("{}: {}", path.display(), err))?;

        if !metadata.is_file() {
            return Err(format!("Expected file, found directory: {}", path.display()));
        }

        match &newest {
            Some((_, current_modified)) if *current_modified > modified => {}
            _ => newest = Some((path.clone(), modified)),
        }
    }

    let (authoritative, authoritative_time) = newest.ok_or("Unable to determine authoritative file")?;
    let authoritative_hash = compute_sha256(&authoritative).map_err(|err| err.to_string())?;

    let mut updates = Vec::new();
    for path in &candidates {
        if path == &authoritative {
            continue;
        }

        let backup_path = backup_path(path);
        fs::copy(path, &backup_path)
            .map_err(|err| format!("Backup failed for {}: {}", path.display(), err))?;

        fs::copy(&authoritative, path)
            .map_err(|err| format!("Sync failed for {}: {}", path.display(), err))?;

        updates.push(json!({
            "target": path.to_string_lossy(),
            "backup": backup_path.to_string_lossy(),
            "sha256": authoritative_hash,
        }));
    }

    let payload = json!({
        "authoritative": authoritative.to_string_lossy(),
        "authoritative_timestamp": authoritative_time.duration_since(UNIX_EPOCH).map(|d| d.as_secs()).unwrap_or_default(),
        "sha256": authoritative_hash,
        "updates": updates
    });

    Ok(payload.to_string())
}

fn push_to_git(path: &str) -> Result<String, String> {
    let repo = repo_dir(path)?;

    let status = Command::new("git")
        .current_dir(&repo)
        .args(["status", "--porcelain"])
        .output()
        .map_err(|err| format!("git status failed: {}", err))?;

    if !status.stdout.is_empty() {
        return Err("Repository has uncommitted changes; aborting push".to_string());
    }

    let push_output = Command::new("git")
        .current_dir(&repo)
        .args(["push", "--atomic"])
        .output()
        .map_err(|err| format!("git push failed: {}", err))?;

    if !push_output.status.success() {
        return Err(format!(
            "git push failed: {}",
            String::from_utf8_lossy(&push_output.stderr)
        ));
    }

    Ok(String::from_utf8_lossy(&push_output.stdout).trim().to_string())
}

fn pull_from_git(path: &str) -> Result<String, String> {
    let repo = repo_dir(path)?;

    let fetch = Command::new("git")
        .current_dir(&repo)
        .args(["fetch", "--prune"])
        .output()
        .map_err(|err| format!("git fetch failed: {}", err))?;

    if !fetch.status.success() {
        return Err(format!(
            "git fetch failed: {}",
            String::from_utf8_lossy(&fetch.stderr)
        ));
    }

    let pull = Command::new("git")
        .current_dir(&repo)
        .args(["pull", "--ff-only"])
        .output()
        .map_err(|err| format!("git pull failed: {}", err))?;

    if !pull.status.success() {
        return Err(format!(
            "git pull failed: {}",
            String::from_utf8_lossy(&pull.stderr)
        ));
    }

    Ok(String::from_utf8_lossy(&pull.stdout).trim().to_string())
}

fn generate_receipt(file: &str) -> Result<String, String> {
    let trimmed = file.trim();
    if trimmed.is_empty() {
        return Err("File path required".to_string());
    }

    let path = Path::new(trimmed);
    if !path.exists() {
        return Err(format!("File not found: {}", path.display()));
    }

    let hash = compute_sha256(path).map_err(|err| err.to_string())?;
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map(|duration| duration.as_secs())
        .unwrap_or_default();

    let receipt = json!({
        "file": path.to_string_lossy(),
        "sha256": hash,
        "timestamp": timestamp,
        "station": std::env::var("STATION_ID").unwrap_or_else(|_| "UNKNOWN".to_string())
    });

    Ok(receipt.to_string())
}

fn validate_receipt(receipt: &str) -> Result<String, String> {
    let parsed: serde_json::Value =
        serde_json::from_str(receipt).map_err(|err| format!("Invalid receipt JSON: {}", err))?;

    let file = parsed
        .get("file")
        .and_then(|value| value.as_str())
        .ok_or("Receipt missing file field")?;
    let expected = parsed
        .get("sha256")
        .and_then(|value| value.as_str())
        .ok_or("Receipt missing sha256 field")?;

    let actual = compute_sha256(Path::new(file)).map_err(|err| err.to_string())?;
    if actual != expected {
        return Err("Receipt mismatch".to_string());
    }

    Ok(json!({
        "file": file,
        "sha256": actual,
        "status": "verified"
    })
    .to_string())
}

fn validate_deployment(package: &str) -> Result<String, String> {
    let trimmed = package.trim();
    if trimmed.is_empty() {
        return Err("Package directory required".to_string());
    }

    let path = Path::new(trimmed);
    if !path.is_dir() {
        return Err(format!("Not a deployment directory: {}", path.display()));
    }

    let required = ["manifest.yaml", "checksums.sha256"];
    let mut missing = Vec::new();

    for file in &required {
        if !path.join(file).exists() {
            missing.push(file.to_string());
        }
    }

    if !missing.is_empty() {
        return Err(format!("Missing deployment artifacts: {}", missing.join(", ")));
    }

    let manifest_content = fs::read_to_string(path.join("manifest.yaml"))
        .map_err(|err| format!("Unable to read manifest.yaml: {}", err))?;

    if !manifest_content.contains("version:") {
        return Err("manifest.yaml missing version field".to_string());
    }

    Ok(json!({
        "package": path.to_string_lossy(),
        "status": "ready",
        "validated": required
    })
    .to_string())
}

fn manage_cloud(input: &str) -> Result<String, String> {
    let parts: Vec<&str> = input.split_whitespace().collect();
    if parts.is_empty() {
        return Err("Provide a cloud action (plan, apply, destroy)".to_string());
    }

    let action = parts[0];
    let config = parts.get(1).copied().unwrap_or("cloud.hcl");
    let config_path = Path::new(config);

    if !config_path.exists() {
        return Err(format!("Cloud config not found: {}", config_path.display()));
    }

    let sha = compute_sha256(config_path).map_err(|err| err.to_string())?;

    Ok(json!({
        "action": action,
        "config": config_path.to_string_lossy(),
        "sha256": sha,
        "status": "validated"
    })
    .to_string())
}

fn track_costs(input: &str) -> Result<String, String> {
    let report_path = Path::new(input.trim());
    if report_path.as_os_str().is_empty() {
        return Err("Usage: <cost-report.json>".to_string());
    }

    let raw = fs::read_to_string(report_path)
        .map_err(|err| format!("Unable to read cost report: {}", err))?;

    let parsed: serde_json::Value =
        serde_json::from_str(&raw).map_err(|err| format!("Invalid cost report JSON: {}", err))?;

    let total = parsed
        .get("services")
        .and_then(|value| value.as_array())
        .map(|services| {
            services
                .iter()
                .filter_map(|service| service.get("monthly").and_then(|value| value.as_f64()))
                .sum::<f64>()
        })
        .unwrap_or_default();

    Ok(json!({
        "report": report_path.to_string_lossy(),
        "total_monthly": total,
        "service_count": parsed.get("services").and_then(|value| value.as_array()).map(|arr| arr.len()).unwrap_or(0)
    })
    .to_string())
}

fn catalog_library(input: &str) -> Result<String, String> {
    let base = Path::new(input.trim());
    if !base.exists() {
        return Err(format!("Library path not found: {}", base.display()));
    }

    let mut entries = Vec::new();
    for entry in WalkDir::new(base)
        .into_iter()
        .filter_map(Result::ok)
        .filter(|entry| entry.file_type().is_file())
    {
        let rel = entry
            .path()
            .strip_prefix(base)
            .unwrap_or(entry.path())
            .to_string_lossy()
            .to_string();

        entries.push(json!({
            "path": rel,
            "bytes": entry.metadata().map(|meta| meta.len()).unwrap_or(0),
        }));
    }

    Ok(json!({
        "root": base.to_string_lossy(),
        "count": entries.len(),
        "entries": entries
    })
    .to_string())
}

fn validate_links(input: &str) -> Result<String, String> {
    let mut issues = Vec::new();
    let mut note_links: HashMap<String, Vec<String>> = HashMap::new();

    for line in input.lines() {
        let parts: Vec<&str> = line.split("->").map(|part| part.trim()).collect();
        if parts.len() != 2 {
            continue;
        }

        note_links
            .entry(parts[0].to_string())
            .or_default()
            .push(parts[1].to_string());
    }

    for (source, targets) in &note_links {
        for target in targets {
            let forward = note_links
                .get(target)
                .map(|links| links.contains(source))
                .unwrap_or(false);

            if !forward {
                issues.push(json!({ "source": source, "target": target }));
            }
        }
    }

    Ok(json!({
        "links_checked": note_links.len(),
        "broken": issues
    })
    .to_string())
}

fn generate_moc(input: &str) -> Result<String, String> {
    let base = Path::new(input.trim());
    if !base.exists() {
        return Err(format!("Knowledge base missing: {}", base.display()));
    }

    let mut topics = HashMap::new();
    for entry in WalkDir::new(base)
        .into_iter()
        .filter_map(Result::ok)
        .filter(|entry| entry.file_type().is_file())
    {
        let content = fs::read_to_string(entry.path()).unwrap_or_default();
        let tags: Vec<&str> = content
            .lines()
            .filter(|line| line.starts_with('#'))
            .collect();

        topics.insert(
            entry
                .path()
                .strip_prefix(base)
                .unwrap_or(entry.path())
                .to_string_lossy()
                .to_string(),
            tags,
        );
    }

    Ok(json!({
        "root": base.to_string_lossy(),
        "topics": topics
    })
    .to_string())
}

fn compute_sha256(path: &Path) -> std::io::Result<String> {
    let mut file = File::open(path)?;
    let mut hasher = Sha256::new();
    let mut buffer = [0u8; 8192];

    loop {
        let read = file.read(&mut buffer)?;
        if read == 0 {
            break;
        }
        hasher.update(&buffer[..read]);
    }

    Ok(format!("{:x}", hasher.finalize()))
}

fn iso_timestamp(time: SystemTime) -> Option<String> {
    let duration = time.duration_since(UNIX_EPOCH).ok()?;
    let seconds = duration.as_secs();
    let nanos = duration.subsec_nanos();
    Some(format!("{}.{:09}Z", seconds, nanos))
}

fn backup_path(path: &Path) -> PathBuf {
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map(|duration| duration.as_secs())
        .unwrap_or_default();

    let mut backup = path.to_path_buf();
    let extension = format!("bak.{}", timestamp);
    backup.set_extension(extension);
    backup
}

fn repo_dir(path: &str) -> Result<PathBuf, String> {
    let trimmed = path.trim();
    let repo = if trimmed.is_empty() { "." } else { trimmed };
    let dir = Path::new(repo);

    if !dir.exists() {
        return Err(format!("Repository path not found: {}", dir.display()));
    }

    dir.canonicalize().map_err(|err| err.to_string())
}

// ============================================================================
// Token Management Implementations
// ============================================================================

/// Token counting configuration
#[derive(Debug, Serialize, Deserialize)]
pub struct TokenInfo {
    pub text: String,
    pub token_count: usize,
    pub model: String,
    pub encoding: String,
}

fn count_tokens(input: &str) -> Result<String, String> {
    // Parse input: format is "model:text" or just "text" (defaults to gpt-4o)
    let (model, text) = if input.contains(':') {
        let parts: Vec<&str> = input.splitn(2, ':').collect();
        (parts[0], parts[1])
    } else {
        ("gpt-4o", input)
    };
    
    // Try to use tiktoken, fallback to estimation
    let (token_count, method) = match try_tiktoken_count(model, text) {
        Ok(count) => (count, "tiktoken"),
        Err(_) => (estimate_tokens(text), "estimated"),
    };
    
    Ok(format!("Tokens: {} ({}) | Model: {} | Text length: {} chars", 
        token_count, method, model, text.len()))
}

fn try_tiktoken_count(model: &str, text: &str) -> Result<usize, String> {
    // Use appropriate tokenizer
    let token_count = match model {
        "gpt-4o" | "gpt-4" | "claude-3" | "claude-sonnet-4" => {
            // Use o200k_base for newer models
            let bpe = o200k_base().map_err(|e| format!("Tokenizer error: {}", e))?;
            bpe.encode_with_special_tokens(text).len()
        }
        "gpt-3.5" | "gpt-3.5-turbo" => {
            // Use cl100k_base for GPT-3.5
            let bpe = cl100k_base().map_err(|e| format!("Tokenizer error: {}", e))?;
            bpe.encode_with_special_tokens(text).len()
        }
        _ => {
            return Err(format!("Unknown model: {}", model));
        }
    };
    
    Ok(token_count)
}

fn estimate_tokens(text: &str) -> usize {
    // Fallback estimation when tiktoken is not available
    // Industry standard: ~4 chars per token for English
    let char_count = text.len();
    let word_count = text.split_whitespace().count();
    
    // Refined estimation: avg 0.75 tokens per word, min 1 token per 4 chars
    let char_based = (char_count as f64 / 4.0).ceil() as usize;
    let word_based = (word_count as f64 * 0.75).ceil() as usize;
    
    char_based.max(word_based).max(1)
}

fn analyze_context(input: &str) -> Result<String, String> {
    // Input format: "model:context1|context2|context3..."
    let parts: Vec<&str> = input.splitn(2, ':').collect();
    let model = if parts.len() == 2 { parts[0] } else { "gpt-4o" };
    let contexts: Vec<&str> = parts.last().unwrap().split('|').collect();
    
    let mut total_tokens = 0;
    let mut analysis = Vec::new();
    
    for (i, ctx) in contexts.iter().enumerate() {
        let count_result = count_tokens(&format!("{}:{}", model, ctx))?;
        let tokens: usize = count_result
            .split_whitespace()
            .nth(1)
            .and_then(|s| s.parse().ok())
            .unwrap_or(0);
        
        total_tokens += tokens;
        analysis.push(format!("  [{}] {} tokens ({} chars)", i, tokens, ctx.len()));
    }
    
    let max_tokens = match model {
        "gpt-4o" | "claude-sonnet-4" => 128_000,
        "gpt-4" => 8_000,
        "gpt-3.5-turbo" => 4_000,
        _ => 8_000,
    };
    
    let percentage = (total_tokens as f64 / max_tokens as f64) * 100.0;
    
    Ok(format!(
        "Context Analysis:\n{}\n\nTotal: {} tokens / {} max ({:.1}% used)\nRemaining: {} tokens",
        analysis.join("\n"),
        total_tokens,
        max_tokens,
        percentage,
        max_tokens - total_tokens
    ))
}

fn estimate_cost(input: &str) -> Result<String, String> {
    // Simple token count summary
    let parts: Vec<&str> = input.split(':').collect();
    if parts.len() < 3 {
        return Err("Format: model:input_tokens:output_tokens".to_string());
    }
    
    let model = parts[0];
    let input_tokens: usize = parts[1].parse().map_err(|_| "Invalid input_tokens")?;
    let output_tokens: usize = parts[2].parse().map_err(|_| "Invalid output_tokens")?;
    let total = input_tokens + output_tokens;
    
    Ok(format!(
        "Token Summary for {}:\n  Input: {}\n  Output: {}\n  Total: {}",
        model, input_tokens, output_tokens, total
    ))
}

// ============================================================================
// Workspace-Specific Toolsets
// ============================================================================

/// RVNx Toolset (Sentinel - Sync & Safety)
pub const RVNX_TOOLS: &[Tool] = &[
    Tool::FileValidator,
    Tool::ConflictResolver,
    Tool::GitPusher,
    Tool::GitPuller,
    Tool::ReceiptGenerator,
    Tool::ReceiptValidator,
    Tool::TokenCounter,
    Tool::ContextAnalyzer,
];

/// SYNTH Toolset (Alchemist - Deploy & Build)
pub const SYNTH_TOOLS: &[Tool] = &[
    Tool::DeployValidator,
    Tool::CloudManager,
    Tool::CostTracker,
    Tool::GitPusher,
    Tool::ReceiptGenerator,
    Tool::TokenCounter,
    Tool::CostEstimator,
];

/// OBSIDIAN Toolset (Lighthouse - Knowledge)
pub const OBSIDIAN_TOOLS: &[Tool] = &[
    Tool::LibraryCatalog,
    Tool::LinkValidator,
    Tool::MOCGenerator,
    Tool::FileValidator,
    Tool::TokenCounter,
    Tool::ContextAnalyzer,
];

pub struct Toolset {
    enabled: Vec<Tool>,
}

impl Toolset {
    /// Load toolset for workspace
    pub fn load_for_workspace(workspace: &str) -> Self {
        let enabled = match workspace {
            "RVNx.BASE" => RVNX_TOOLS.to_vec(),
            "SYNTH.BASE" => SYNTH_TOOLS.to_vec(),
            "OBSIDIAN.BASE" => OBSIDIAN_TOOLS.to_vec(),
            _ => vec![],
        };
        
        Self { enabled }
    }
    
    /// Execute tool by name
    pub fn run(&self, tool_name: &str, input: &str) -> Result<String, String> {
        for tool in &self.enabled {
            if format!("{:?}", tool) == tool_name {
                return tool.execute(input);
            }
        }
        Err(format!("Tool not found or not enabled: {}", tool_name))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use tempfile::NamedTempFile;

    #[test]
    fn file_validator_includes_hash() {
        let mut temp = NamedTempFile::new().expect("temp file");
        writeln!(temp, "hello world").expect("write");
        let path = temp.path().to_string_lossy().to_string();

        let result = validate_file(&path).expect("validation");
        assert!(result.contains("\"sha256\""));
        assert!(result.contains("\"status\":\"valid\""));
    }

    #[test]
    fn receipt_round_trip() {
        let mut temp = NamedTempFile::new().expect("temp file");
        writeln!(temp, "hello receipt").expect("write");
        let path = temp.path().to_string_lossy().to_string();

        let receipt_raw = generate_receipt(&path).expect("generate");
        let verified = validate_receipt(&receipt_raw).expect("validate");

        assert!(verified.contains("\"status\":\"verified\""));
    }
}

///▙▖▙▖▞▞▙▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ v2.1.0 | ⧗-25.61 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂///
